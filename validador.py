import streamlit as st
import pandas as pd
import numpy as np
import io
import re

st.set_page_config(page_title="Validador Excel", layout="centered")
st.title("üìä Validador y Analizador de Archivos Excel")

def normalize_text(val):
    if pd.isna(val):
        return ""
    return re.sub(r"\s+", "", str(val)).strip().lower()

def parse_number(val):
    """Interpreta n√∫meros siguiendo la regla: '.' es separador decimal y ',' separador de miles.
    Ejemplos v√°lidos: '1,234.56' -> 1234.56; '1234.56' -> 1234.56; '1.234' -> 1.234 (punto decimal);
    '1,234' -> 1234 (coma como separador de miles); '1234' -> 1234.
    Tambi√©n maneja espacios y valores vac√≠os."""
    try:
        if val is None:
            return np.nan
        s = str(val).strip()
        if s == "" or s.lower() in {"nan", "none"}:
            return np.nan
        # Eliminar espacios intermedios
        s = re.sub(r"\s+", "", s)
        # Si hay al menos un punto, lo tratamos como decimal.
        # Eliminamos las comas que act√∫an como separador de miles.
        if "." in s:
            s = s.replace(",", "")  # coma = miles -> eliminar
            # ahora s tiene punto(s). Si hay m√∫ltiples puntos, solo el √∫ltimo se considera decimal:
            if s.count(".") > 1:
                # unir los posibles miles con puntos y dejar √∫ltimo como decimal: 1.234.567.89 -> 1234567.89
                parts = s.split(".")
                s = "".join(parts[:-1]) + "." + parts[-1]
            return float(s)
        else:
            # No hay punto. Las comas se consideran separador de miles -> eliminar y parsear entero
            s = s.replace(",", "")
            return float(s)
    except:
        return np.nan

def safe_str_preserve(val):
    if pd.isna(val):
        return ""
    s = str(val)
    s = re.sub(r"\.0+$", "", s)
    return s

# Centrar uploader y controles usando columnas
col_left, col_center, col_right = st.columns([1, 2, 1])
with col_center:
    uploaded_files = st.file_uploader("üìÅ Suba uno o varios archivos Excel", type=["xlsx"], accept_multiple_files=True)

if uploaded_files:
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        search_term = st.text_input("üîç Ingrese texto o n√∫mero a buscar (coincidencia exacta, sin espacios)")
        threshold = st.number_input("‚öôÔ∏è Umbral para columna M (ej. 30000)", min_value=0, value=30000)

    error_log = []
    duplicates_report = []
    threshold_report = []
    validation_report = []

    for file in uploaded_files:
        try:
            # Leer todo como string para preservar ceros iniciales
            df = pd.read_excel(file, header=0, dtype=str)
            df.columns = [str(col) for col in df.columns]

            # Helper: obtener nombre de columna por letra (indexaci√≥n por posici√≥n)
            def get_col_by_letter(letter):
                try:
                    idx = ord(letter.upper()) - ord("A")
                    return df.columns[idx]
                except:
                    return None

            # Subt√≠tulo 1: b√∫squeda en todo el archivo
            if search_term:
                norm = df.applymap(lambda x: normalize_text(x))
                target = normalize_text(search_term)
                found_mask = norm.isin([target])
                match_rows = df[found_mask.any(axis=1)]
                match_rows_display = match_rows.copy()
                match_rows_display["Archivo"] = file.name
                st.subheader(f"üìå Coincidencias en archivo: {file.name}")
                if not match_rows_display.empty:
                    st.dataframe(match_rows_display)
                else:
                    st.info(f"No se encontraron coincidencias en {file.name}.")

            # Subt√≠tulo 2: duplicados en M, I, C
            for letter in ["M", "I", "C"]:
                colname = get_col_by_letter(letter)
                if colname is None:
                    error_log.append(f"‚ùå Columna {letter} no encontrada en {file.name}")
                    continue
                try:
                    dups = df[df.duplicated(subset=[colname], keep=False) & df[colname].notna()]
                    if not dups.empty:
                        dups_report = dups.copy()
                        dups_report["Archivo"] = file.name
                        dups_report["Columna duplicada"] = letter
                        duplicates_report.append(dups_report)
                except Exception as e:
                    error_log.append(f"‚ùå Error detectando duplicados en columna {letter} de {file.name}: {e}")

            # Subt√≠tulo 3: threshold en M y extracci√≥n B,C,D,L,M
            col_M = get_col_by_letter("M")
            if col_M is None:
                error_log.append(f"‚ùå Columna M no encontrada en {file.name}")
            else:
                try:
                    # Aplicar parse_number que interpreta '.' como decimal y ',' como miles
                    df["_M_num"] = df[col_M].apply(parse_number)
                    filtered = df[df["_M_num"] >= threshold]
                    extract_letters = ["B", "C", "D", "L", "M"]
                    extract_cols = []
                    missing_extract = []
                    for lt in extract_letters:
                        c = get_col_by_letter(lt)
                        if c is None:
                            missing_extract.append(lt)
                        else:
                            extract_cols.append(c)
                    if filtered is not None and not filtered.empty and not missing_extract:
                        out = filtered[extract_cols].copy()
                        out["Archivo"] = file.name
                        threshold_report.append(out)
                    elif missing_extract:
                        error_log.append(f"‚ùå Columnas faltantes para extracci√≥n {missing_extract} en {file.name}")
                except Exception as e:
                    error_log.append(f"‚ùå Error procesando threshold en {file.name}: {e}")

            # Subt√≠tulo 4: validaci√≥n B -> C (DNI 8, CEX 9, RUC 11)
            col_B = get_col_by_letter("B")
            col_C = get_col_by_letter("C")
            if col_B is None or col_C is None:
                error_log.append(f"‚ùå Columnas B o C faltantes en {file.name}")
            else:
                try:
                    df["_tipo_doc"] = df[col_B].astype(str).apply(lambda x: safe_str_preserve(x).strip().upper())
                    df["_num_doc"] = df[col_C].astype(str).apply(lambda x: safe_str_preserve(x).strip())

                    def validate_row_std(tipo, valor_raw):
                        if valor_raw == "" or valor_raw.lower() in {"nan", "none"}:
                            if tipo in {"DNI", "CEX", "RUC"}:
                                return f"{tipo} inv√°lido - vac√≠o"
                            return None
                        if tipo == "DNI":
                            if not valor_raw.isdigit() or len(valor_raw) != 8:
                                return "DNI inv√°lido"
                            return None
                        elif tipo == "CEX":
                            valor_cex = valor_raw.zfill(9)
                            if not valor_cex.isdigit() or len(valor_cex) != 9:
                                return "CEX inv√°lido"
                            return None
                        elif tipo == "RUC":
                            valor_ruc = valor_raw.zfill(11)
                            if not valor_ruc.isdigit() or len(valor_ruc) != 11:
                                return "RUC inv√°lido"
                            return None
                        return None

                    df["_Error_validacion"] = df.apply(lambda r: validate_row_std(r["_tipo_doc"], r["_num_doc"]), axis=1)
                    errores = df[df["_Error_validacion"].notna()].copy()
                    if not errores.empty:
                        report = pd.DataFrame({
                            "TipoDocumento": errores["_tipo_doc"].values,
                            "Documento": errores["_num_doc"].values,
                            "Error": errores["_Error_validacion"].values,
                            "Archivo": file.name
                        })
                        validation_report.append(report)
                except Exception as e:
                    error_log.append(f"‚ùå Error en validaci√≥n B/C en {file.name}: {e}")

        except Exception as e:
            error_log.append(f"‚ùå Error procesando {file.name}: {e}")

    # Mostrar errores de procesamiento
    if error_log:
        st.subheader("üö® Errores detectados")
        for err in error_log:
            st.error(err)

    # Duplicados
    if duplicates_report:
        st.subheader("üìã Duplicados detectados")
        dup_df = pd.concat(duplicates_report, ignore_index=True)
        st.dataframe(dup_df)
        buf = io.BytesIO()
        with pd.ExcelWriter(buf, engine="xlsxwriter") as writer:
            dup_df.to_excel(writer, index=False, sheet_name="duplicados")
        st.download_button("‚¨áÔ∏è Descargar duplicados", data=buf.getvalue(), file_name="duplicados.xlsx")

    # Threshold
    if threshold_report:
        st.subheader("üìà Filas con M >= threshold")
        th_df = pd.concat(threshold_report, ignore_index=True)
        st.dataframe(th_df)
        buf = io.BytesIO()
        with pd.ExcelWriter(buf, engine="xlsxwriter") as writer:
            th_df.to_excel(writer, index=False, sheet_name="filtrados_threshold")
        st.download_button("‚¨áÔ∏è Descargar filtrados por threshold", data=buf.getvalue(), file_name="filtrados_threshold.xlsx")

    # Validaciones B/C (secci√≥n garantizada)
    st.subheader("üß™ Validaciones de formato B/C (solo errores)")
    if validation_report:
        val_df = pd.concat(validation_report, ignore_index=True)
        st.dataframe(val_df)
        buf = io.BytesIO()
        with pd.ExcelWriter(buf, engine="xlsxwriter") as writer:
            val_df.to_excel(writer, index=False, sheet_name="errores_validacion")
        st.download_button("‚¨áÔ∏è Descargar errores de validaci√≥n", data=buf.getvalue(), file_name="errores_validacion.xlsx")
    else:
        st.info("No se detectaron errores de validaci√≥n B/C.")
